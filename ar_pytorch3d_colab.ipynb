{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1d5582",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“ Assignment 4 â€” Augmented Reality with PyTorch3D\n",
    "\n",
    "This notebook runs **end-to-end** on Google Colab:\n",
    "\n",
    "- Calibrate camera (optional but recommended).\n",
    "- Estimate pose of a **planar surface** (ArUco / checkerboard).\n",
    "- Render a synthetic 3D object using **PyTorch3D**.\n",
    "- Composite the render **onto your real image**.\n",
    "\n",
    "> **Tip**: Use a **flat**, **well-lit** surface. ArUco is the easiest path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3ca7e",
   "metadata": {},
   "source": [
    "## 1) Setup & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7649f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing: opencv-contrib-python==4.10.0.84\n",
      "Installing: numpy\n",
      "Installing: matplotlib\n",
      "Installing: imageio\n",
      "Torch version: 2.2.2\n",
      "CUDA version in torch: None\n",
      "Installing PyTorch3D...\n",
      "Falling back to source install (this can take longer).\n",
      "Installing: 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/pytorch3d.git@stable'\": Expected package name at the start of dependency specifier\n",
      "    'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
      "    ^\n",
      "Hint: It looks like a path. File ''git+https://github.com/facebookresearch/pytorch3d.git@stable'' does not exist.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/Users/prerak/anaconda3/bin/python', '-m', 'pip', 'install', '-q', \"'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"]' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch3D already available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch3d'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstalling PyTorch3D...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m     install_pytorch3d()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll installs finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m, in \u001b[0;36minstall_pytorch3d\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to source install (this can take longer).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     pip_install([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit+https://github.com/facebookresearch/pytorch3d.git@stable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstalling PyTorch3D wheel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, url)\n",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m, in \u001b[0;36mpip_install\u001b[0;34m(pkgs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pkgs:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstalling:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p)\n\u001b[0;32m----> 8\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcheck_call([sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-q\u001b[39m\u001b[38;5;124m\"\u001b[39m, p])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:413\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/Users/prerak/anaconda3/bin/python', '-m', 'pip', 'install', '-q', \"'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"]' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "\n",
    "# If you're on Google Colab, run this cell.\n",
    "def main():\n",
    "    import sys, subprocess, importlib, os, platform\n",
    "\n",
    "    def pip_install(pkgs):\n",
    "        for p in pkgs:\n",
    "            print(\"Installing:\", p)\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", p])\n",
    "\n",
    "    # Core packages\n",
    "    pip_install([\n",
    "        \"opencv-contrib-python==4.10.0.84\",\n",
    "        \"numpy\",\n",
    "        \"matplotlib\",\n",
    "        \"imageio\"\n",
    "    ])\n",
    "\n",
    "    # Torch & PyTorch3D installer (tries to match CUDA/torch).\n",
    "    # Colab usually has torch preinstalled. We detect and install a matching PyTorch3D wheel.\n",
    "    import torch\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    cuda = torch.version.cuda\n",
    "    print(\"CUDA version in torch:\", cuda)\n",
    "\n",
    "    def install_pytorch3d():\n",
    "        # Mapping common CUDA versions to official wheels\n",
    "        wheels = {\n",
    "            \"12.1\": \"https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/cu121/py3.10_pyt2.3.0/pytorch3d-0.7.7-cp310-cp310-linux_x86_64.whl\",\n",
    "            \"11.8\": \"https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/cu118/py3.10_pyt2.1.0/pytorch3d-0.7.5-cp310-cp310-linux_x86_64.whl\",\n",
    "            \"11.7\": \"https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/cu117/py3.10_pyt2.0.1/pytorch3d-0.7.4-cp310-cp310-linux_x86_64.whl\"\n",
    "        }\n",
    "        url = None\n",
    "        if cuda is not None:\n",
    "            # Pick closest\n",
    "            if cuda.startswith(\"12.1\"):\n",
    "                url = wheels[\"12.1\"]\n",
    "            elif cuda.startswith(\"11.8\"):\n",
    "                url = wheels[\"11.8\"]\n",
    "            elif cuda.startswith(\"11.7\"):\n",
    "                url = wheels[\"11.7\"]\n",
    "        if url is None:\n",
    "            print(\"Falling back to source install (this can take longer).\")\n",
    "            pip_install([\"'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"])\n",
    "        else:\n",
    "            print(\"Installing PyTorch3D wheel:\", url)\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", url])\n",
    "\n",
    "    try:\n",
    "        import pytorch3d\n",
    "        print(\"PyTorch3D already available.\")\n",
    "    except Exception as e:\n",
    "        print(\"Installing PyTorch3D...\")\n",
    "        install_pytorch3d()\n",
    "\n",
    "    print(\"All installs finished.\")\n",
    "\n",
    "    import os, sys, cv2, json, math, numpy as np, torch, imageio, matplotlib.pyplot as plt\n",
    "    from google.colab import files\n",
    "\n",
    "    # Download helper modules from this notebook's GitHub or upload manually.\n",
    "    # For this scaffold, we let users upload the helper files generated.\n",
    "    print(\"Please upload pose_utils.py and render_utils.py from the provided ZIP (or your repo).\")\n",
    "\n",
    "    uploaded = files.upload()  # user uploads two .py files here\n",
    "\n",
    "    for name in uploaded.keys():\n",
    "        print(\"Saved\", name)\n",
    "        if name.endswith(\".py\"):\n",
    "            pass\n",
    "\n",
    "    from importlib import reload\n",
    "    import pose_utils, render_utils\n",
    "    reload(pose_utils); reload(render_utils)\n",
    "\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    do_calibrate = True  # set False if you already know K\n",
    "    board_size = (8,6)   # inner corners\n",
    "    square_size = 0.024  # 24 mm squares -> 0.024 m\n",
    "\n",
    "    K = None\n",
    "    dist = None\n",
    "    img_size = None\n",
    "\n",
    "    if do_calibrate:\n",
    "        print(\"Upload checkerboard images...\")\n",
    "        up = files.upload()\n",
    "        image_files = [k for k in up.keys() if k.lower().endswith((\".jpg\",\".png\",\".jpeg\"))]\n",
    "        print(\"Found\", len(image_files), \"images\")\n",
    "        K, dist, rms, img_size = pose_utils.calibrate_from_checkerboard(image_files, board_size, square_size)\n",
    "        print(\"Calibration RMS:\", rms)\n",
    "        print(\"K =\\\\n\", K)\n",
    "        print(\"dist =\", dist.ravel())\n",
    "    else:\n",
    "        print(\"Skipping calibration; you will set K manually in next cell.\")\n",
    "        \n",
    "\n",
    "    # If you skipped calibration, manually define K here:\n",
    "    use_manual_K = False\n",
    "    manual_fx, manual_fy, manual_cx, manual_cy = 1200.0, 1200.0, 640.0, 360.0\n",
    "\n",
    "    if use_manual_K:\n",
    "        K = np.array([[manual_fx, 0, manual_cx],\n",
    "                    [0, manual_fy, manual_cy],\n",
    "                    [0, 0, 1]], dtype=np.float32)\n",
    "        dist = np.zeros((5,1), dtype=np.float32)\n",
    "        img_size = (int(manual_cx*2), int(manual_cy*2))\n",
    "        print(\"Manual K set.\")\n",
    "        print(K)\n",
    "\n",
    "\n",
    "    print(\"Upload your real image (with ArUco or checkerboard visible).\")\n",
    "    up2 = files.upload()\n",
    "    img_name = next(iter(up2.keys()))\n",
    "    img_bgr = cv2.imread(img_name)\n",
    "    H_img, W_img = img_bgr.shape[:2]\n",
    "    print(\"Image size:\", (H_img, W_img))\n",
    "    plt.figure(); plt.imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)); plt.title(\"Input\"); plt.axis(\"off\");\n",
    "\n",
    "\n",
    "\n",
    "    use_aruco = True\n",
    "    aruco_id = 0       # set to match the marker ID you printed\n",
    "    marker_length = 0.04  # 4 cm in meters\n",
    "\n",
    "    R = None; T = None\n",
    "    if use_aruco:\n",
    "        R, T, corners = pose_utils.estimate_pose_from_aruco(img_bgr, K, dist, aruco_id=aruco_id, marker_length=marker_length)\n",
    "        print(\"R=\\\\n\", R)\n",
    "        print(\"T=\", T)\n",
    "        img_axes = img_bgr.copy()\n",
    "        # Draw axes for visualization\n",
    "        axis_len = marker_length*0.5\n",
    "        axis = np.float32([[0,0,0],[axis_len,0,0],[0,axis_len,0],[0,0,axis_len]])\n",
    "        rvec, _ = cv2.Rodrigues(R)\n",
    "        imgpts, _ = cv2.projectPoints(axis, rvec, T, K, dist)\n",
    "        imgpts = imgpts.reshape(-1,2).astype(int)\n",
    "        img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[1]), (0,0,255), 2)\n",
    "        img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[2]), (0,255,0), 2)\n",
    "        img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[3]), (255,0,0), 2)\n",
    "        plt.figure(); plt.imshow(cv2.cvtColor(img_axes, cv2.COLOR_BGR2RGB)); plt.title(\"Pose axes on ArUco\"); plt.axis(\"off\");\n",
    "    else:\n",
    "        # Example: estimate homography from four known world points on the plane and their image points\n",
    "        # (You can adapt this section to your checkerboard corners.)\n",
    "        raise NotImplementedError(\"Set use_aruco=True or implement homography-based pose here.\")\n",
    "\n",
    "    from render_utils import build_pytorch3d_camera_from_KRT\n",
    "    cameras = build_pytorch3d_camera_from_KRT(K, R, T, (H_img, W_img))\n",
    "    cameras\n",
    "\n",
    "    from render_utils import make_colored_cube, build_renderer, composite_on_image\n",
    "\n",
    "    mesh = make_colored_cube(side=0.06, center=(0,0,0)).to(device)\n",
    "    renderer = build_renderer(cameras, (H_img, W_img))\n",
    "    image = renderer(meshes_world=mesh, cameras=cameras)\n",
    "    rgb = image[0, ..., :3].detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8,6)); plt.imshow(rgb); plt.title(\"Rendered RGB\"); plt.axis(\"off\");\n",
    "\n",
    "    comp = composite_on_image(rgb, img_bgr)\n",
    "    plt.figure(figsize=(8,6)); plt.imshow(cv2.cvtColor(comp, cv2.COLOR_BGR2RGB)); plt.title(\"AR Composite\"); plt.axis(\"off\");\n",
    "\n",
    "    out_name = \"ar_composite.png\"\n",
    "    cv2.imwrite(out_name, comp)\n",
    "    print(\"Saved:\", out_name)\n",
    "    files.download(out_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949ebca",
   "metadata": {},
   "source": [
    "## 2) Imports & Helper Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, cv2, json, math, numpy as np, torch, imageio, matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "\n",
    "# Download helper modules from this notebook's GitHub or upload manually.\n",
    "# For this scaffold, we let users upload the helper files generated.\n",
    "print(\"Please upload pose_utils.py and render_utils.py from the provided ZIP (or your repo).\")\n",
    "\n",
    "uploaded = files.upload()  # user uploads two .py files here\n",
    "\n",
    "for name in uploaded.keys():\n",
    "    print(\"Saved\", name)\n",
    "    if name.endswith(\".py\"):\n",
    "        pass\n",
    "\n",
    "from importlib import reload\n",
    "import pose_utils, render_utils\n",
    "reload(pose_utils); reload(render_utils)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d7cf5",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Option A â€” Calibrate Intrinsics from Checkerboard (Recommended)\n",
    "\n",
    "Upload **5â€“15** images of a standard checkerboard (8x6 inner corners). Set the `square_size` in **meters**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81021f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "do_calibrate = True  # set False if you already know K\n",
    "board_size = (8,6)   # inner corners\n",
    "square_size = 0.024  # 24 mm squares -> 0.024 m\n",
    "\n",
    "K = None\n",
    "dist = None\n",
    "img_size = None\n",
    "\n",
    "if do_calibrate:\n",
    "    print(\"Upload checkerboard images...\")\n",
    "    up = files.upload()\n",
    "    image_files = [k for k in up.keys() if k.lower().endswith((\".jpg\",\".png\",\".jpeg\"))]\n",
    "    print(\"Found\", len(image_files), \"images\")\n",
    "    K, dist, rms, img_size = pose_utils.calibrate_from_checkerboard(image_files, board_size, square_size)\n",
    "    print(\"Calibration RMS:\", rms)\n",
    "    print(\"K =\\\\n\", K)\n",
    "    print(\"dist =\", dist.ravel())\n",
    "else:\n",
    "    print(\"Skipping calibration; you will set K manually in next cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae7953",
   "metadata": {},
   "source": [
    "\n",
    "## 3b) Option B â€” Enter Known Intrinsics\n",
    "\n",
    "If you already have intrinsics (`fx, fy, cx, cy`), set them here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you skipped calibration, manually define K here:\n",
    "use_manual_K = False\n",
    "manual_fx, manual_fy, manual_cx, manual_cy = 1200.0, 1200.0, 640.0, 360.0\n",
    "\n",
    "if use_manual_K:\n",
    "    K = np.array([[manual_fx, 0, manual_cx],\n",
    "                  [0, manual_fy, manual_cy],\n",
    "                  [0, 0, 1]], dtype=np.float32)\n",
    "    dist = np.zeros((5,1), dtype=np.float32)\n",
    "    img_size = (int(manual_cx*2), int(manual_cy*2))\n",
    "    print(\"Manual K set.\")\n",
    "    print(K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a866bee",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Pose Estimation from a Planar Target\n",
    "\n",
    "We provide two easy paths:\n",
    "- **ArUco marker** (recommended): print a 4x4_50 dictionary marker with **ID=0** (or any ID you set).\n",
    "- **Checkerboard**: if you don't have ArUco, you can estimate pose from a checkerboard corner grid.\n",
    "\n",
    "Upload **one** real-world image with the marker/board visible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Upload your real image (with ArUco or checkerboard visible).\")\n",
    "up2 = files.upload()\n",
    "img_name = next(iter(up2.keys()))\n",
    "img_bgr = cv2.imread(img_name)\n",
    "H_img, W_img = img_bgr.shape[:2]\n",
    "print(\"Image size:\", (H_img, W_img))\n",
    "plt.figure(); plt.imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)); plt.title(\"Input\"); plt.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baab538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_aruco = True\n",
    "aruco_id = 0       # set to match the marker ID you printed\n",
    "marker_length = 0.04  # 4 cm in meters\n",
    "\n",
    "R = None; T = None\n",
    "if use_aruco:\n",
    "    R, T, corners = pose_utils.estimate_pose_from_aruco(img_bgr, K, dist, aruco_id=aruco_id, marker_length=marker_length)\n",
    "    print(\"R=\\\\n\", R)\n",
    "    print(\"T=\", T)\n",
    "    img_axes = img_bgr.copy()\n",
    "    # Draw axes for visualization\n",
    "    axis_len = marker_length*0.5\n",
    "    axis = np.float32([[0,0,0],[axis_len,0,0],[0,axis_len,0],[0,0,axis_len]])\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    imgpts, _ = cv2.projectPoints(axis, rvec, T, K, dist)\n",
    "    imgpts = imgpts.reshape(-1,2).astype(int)\n",
    "    img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[1]), (0,0,255), 2)\n",
    "    img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[2]), (0,255,0), 2)\n",
    "    img_axes = cv2.line(img_axes, tuple(imgpts[0]), tuple(imgpts[3]), (255,0,0), 2)\n",
    "    plt.figure(); plt.imshow(cv2.cvtColor(img_axes, cv2.COLOR_BGR2RGB)); plt.title(\"Pose axes on ArUco\"); plt.axis(\"off\");\n",
    "else:\n",
    "    # Example: estimate homography from four known world points on the plane and their image points\n",
    "    # (You can adapt this section to your checkerboard corners.)\n",
    "    raise NotImplementedError(\"Set use_aruco=True or implement homography-based pose here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20451f54",
   "metadata": {},
   "source": [
    "## 5) Build PyTorch3D Camera from K, R, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b42b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from render_utils import build_pytorch3d_camera_from_KRT\n",
    "cameras = build_pytorch3d_camera_from_KRT(K, R, T, (H_img, W_img))\n",
    "cameras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de156a71",
   "metadata": {},
   "source": [
    "## 6) Create a Mesh & Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from render_utils import make_colored_cube, build_renderer, composite_on_image\n",
    "\n",
    "mesh = make_colored_cube(side=0.06, center=(0,0,0)).to(device)\n",
    "renderer = build_renderer(cameras, (H_img, W_img))\n",
    "image = renderer(meshes_world=mesh, cameras=cameras)\n",
    "rgb = image[0, ..., :3].detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(8,6)); plt.imshow(rgb); plt.title(\"Rendered RGB\"); plt.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621d4ec",
   "metadata": {},
   "source": [
    "## 7) Composite the Render onto the Real Image & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comp = composite_on_image(rgb, img_bgr)\n",
    "plt.figure(figsize=(8,6)); plt.imshow(cv2.cvtColor(comp, cv2.COLOR_BGR2RGB)); plt.title(\"AR Composite\"); plt.axis(\"off\");\n",
    "\n",
    "out_name = \"ar_composite.png\"\n",
    "cv2.imwrite(out_name, comp)\n",
    "print(\"Saved:\", out_name)\n",
    "files.download(out_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e19c8f",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (Optional) Swap Mesh / Align to Plane\n",
    "\n",
    "- Replace the cube with your own mesh (e.g., OBJ) using `pytorch3d.io.load_objs_as_meshes`.\n",
    "- Translate/rotate the mesh so it **rests on** your real plane. For ArUco, you can define the plane as Z=0 in the marker frame.\n",
    "- Scale the mesh in **meters** so size matches your scene.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
